{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f44e4ee4",
   "metadata": {},
   "source": [
    "#  ðŸ“ˆ Exploratory Data Analysis and Visualization\n",
    "# \n",
    "# **IMPORTANT**: This notebook **LOADS DATA** using the existing functions \n",
    "# \n",
    "#  Objectives:\n",
    "# - âœ… Statistical analysis (NEW)\n",
    "# - âœ… Correlation analysis (NEW) \n",
    "# - âœ… Trend analysis (NEW)\n",
    "# - âœ… Volatility analysis (NEW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1982cd8",
   "metadata": {},
   "source": [
    "#  Load Previously Downloaded Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da455e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from data import load_raw_data, calculate_returns\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Load data that was already downloaded in notebook 01\n",
    "tickers = ['AAPL', 'GOOGL', 'MSFT', 'TSLA', 'AMZN']\n",
    "stock_data = {}\n",
    "for ticker in tickers:\n",
    "    stock_data[ticker] = load_raw_data(f'../data/raw/{ticker}.csv')\n",
    "    print(f\"âœ… Loaded {ticker}: {stock_data[ticker].shape[0]} records\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Loaded {len(stock_data)} stocks for EDA analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ddedde",
   "metadata": {},
   "source": [
    "#  Statistical Summary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e442cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ“Š STATISTICAL SUMMARY ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Calculate key statistics for each stock\n",
    "summary_stats = {}\n",
    "for ticker in tickers:\n",
    "    data = stock_data[ticker]\n",
    "    returns = calculate_returns(data['Close'])\n",
    "\n",
    "    summary_stats[ticker] = {\n",
    "        'Mean_Price': data['Close'].mean(),\n",
    "        'Std_Price': data['Close'].std(),\n",
    "        'Min_Price': data['Close'].min(),\n",
    "        'Max_Price': data['Close'].max(),\n",
    "        'Mean_Return': returns.mean(),\n",
    "        'Std_Return': returns.std(),\n",
    "        'Skewness': returns.skew(),\n",
    "        'Kurtosis': returns.kurtosis(),\n",
    "        'Sharpe_Ratio': returns.mean() / returns.std() * np.sqrt(252),\n",
    "        'Max_Drawdown': ((data['Close'] / data['Close'].expanding().max()) - 1).min()\n",
    "    }\n",
    "\n",
    "# Convert to DataFrame for better visualization\n",
    "stats_df = pd.DataFrame(summary_stats).T\n",
    "print(\"Key Statistics by Stock:\")\n",
    "print(stats_df.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d17eff",
   "metadata": {},
   "source": [
    "#  Returns Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afc67e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸ“ˆ RETURNS DISTRIBUTION ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Calculate returns for all stocks\n",
    "returns_data = {}\n",
    "for ticker in tickers:\n",
    "    returns_data[ticker] = calculate_returns(stock_data[ticker]['Close'])\n",
    "\n",
    "returns_df = pd.DataFrame(returns_data)\n",
    "\n",
    "# Create distribution analysis plot\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('Returns Distribution Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Individual histograms\n",
    "for i, ticker in enumerate(tickers):\n",
    "    row, col = i // 3, i % 3\n",
    "    ax = axes[row, col]\n",
    "\n",
    "    returns_data[ticker].hist(bins=50, alpha=0.7, ax=ax)\n",
    "    ax.set_title(f'{ticker} Returns Distribution')\n",
    "    ax.set_xlabel('Daily Returns')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # Add normal distribution overlay\n",
    "    mu, sigma = returns_data[ticker].mean(), returns_data[ticker].std()\n",
    "    x = np.linspace(returns_data[ticker].min(),\n",
    "                    returns_data[ticker].max(), 100)\n",
    "    normal_curve = stats.norm.pdf(\n",
    "        x, mu, sigma) * len(returns_data[ticker]) * (x[1] - x[0])\n",
    "    ax.plot(x, normal_curve, 'r-', linewidth=2, label='Normal')\n",
    "    ax.legend()\n",
    "\n",
    "# Combined box plot\n",
    "axes[1, 2].boxplot([returns_data[ticker].dropna() for ticker in tickers],\n",
    "                   labels=tickers)\n",
    "axes[1, 2].set_title('Returns Box Plot Comparison')\n",
    "axes[1, 2].set_ylabel('Daily Returns')\n",
    "axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Normality tests\n",
    "print(\"\\nNormality Test Results (Shapiro-Wilk):\")\n",
    "for ticker in tickers:\n",
    "    sample = returns_data[ticker].dropna().sample(\n",
    "        min(5000, len(returns_data[ticker])))\n",
    "    stat, p_value = stats.shapiro(sample)\n",
    "    normal = \"âœ… Normal\" if p_value > 0.05 else \"âŒ Non-normal\"\n",
    "    print(f\"{ticker}: p-value = {p_value:.2e} ({normal})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82be2c73",
   "metadata": {},
   "source": [
    "#  Correlation Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32791d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸ”— CORRELATION ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Price correlations\n",
    "price_df = pd.DataFrame(\n",
    "    {ticker: stock_data[ticker]['Close'] for ticker in tickers})\n",
    "price_corr = price_df.corr()\n",
    "\n",
    "# Returns correlations\n",
    "returns_corr = returns_df.corr()\n",
    "\n",
    "# Volume correlations\n",
    "volume_df = pd.DataFrame(\n",
    "    {ticker: stock_data[ticker]['Volume'] for ticker in tickers})\n",
    "volume_corr = volume_df.corr()\n",
    "\n",
    "# Create correlation heatmaps\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "fig.suptitle('Correlation Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Price correlations\n",
    "sns.heatmap(price_corr, annot=True, cmap='coolwarm', center=0,\n",
    "            ax=axes[0], cbar_kws={'label': 'Correlation'})\n",
    "axes[0].set_title('Price Correlations')\n",
    "\n",
    "# Returns correlations\n",
    "sns.heatmap(returns_corr, annot=True, cmap='coolwarm', center=0,\n",
    "            ax=axes[1], cbar_kws={'label': 'Correlation'})\n",
    "axes[1].set_title('Returns Correlations')\n",
    "\n",
    "# Volume correlations\n",
    "sns.heatmap(volume_corr, annot=True, cmap='coolwarm', center=0,\n",
    "            ax=axes[2], cbar_kws={'label': 'Correlation'})\n",
    "axes[2].set_title('Volume Correlations')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print highest correlations\n",
    "print(\"Highest Returns Correlations:\")\n",
    "returns_corr_flat = returns_corr.where(\n",
    "    np.triu(np.ones(returns_corr.shape), k=1).astype(bool))\n",
    "high_corr = returns_corr_flat.stack().sort_values(ascending=False)\n",
    "for pair, corr in high_corr.head(3).items():\n",
    "    print(f\"{pair[0]} - {pair[1]}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411a1f85",
   "metadata": {},
   "source": [
    "#  Trend Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c930c698",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸ“Š TREND ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Calculate moving averages and trends\n",
    "trend_data = {}\n",
    "for ticker in tickers:\n",
    "    data = stock_data[ticker].copy()\n",
    "\n",
    "    # Moving averages\n",
    "    data['MA_20'] = data['Close'].rolling(20).mean()\n",
    "    data['MA_50'] = data['Close'].rolling(50).mean()\n",
    "    data['MA_200'] = data['Close'].rolling(200).mean()\n",
    "\n",
    "    # Trend indicators\n",
    "    data['Trend_20_50'] = data['MA_20'] > data['MA_50']\n",
    "    data['Trend_50_200'] = data['MA_50'] > data['MA_200']\n",
    "    data['Golden_Cross'] = data['Trend_20_50'] & data['Trend_50_200']\n",
    "\n",
    "    trend_data[ticker] = data\n",
    "\n",
    "# Trend analysis visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "fig.suptitle('Trend Analysis with Moving Averages',\n",
    "             fontsize=16, fontweight='bold')\n",
    "\n",
    "for i, ticker in enumerate(tickers):\n",
    "    row, col = i // 3, i % 3\n",
    "    ax = axes[row, col]\n",
    "\n",
    "    data = trend_data[ticker]\n",
    "\n",
    "    # Plot prices and moving averages\n",
    "    ax.plot(data.index, data['Close'], label='Close', linewidth=1, alpha=0.8)\n",
    "    ax.plot(data.index, data['MA_20'], label='MA 20', linewidth=1)\n",
    "    ax.plot(data.index, data['MA_50'], label='MA 50', linewidth=1)\n",
    "    ax.plot(data.index, data['MA_200'], label='MA 200', linewidth=1)\n",
    "\n",
    "    ax.set_title(f'{ticker} - Price & Moving Averages')\n",
    "    ax.set_ylabel('Price ($)')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Golden Cross analysis for last subplot\n",
    "axes[1, 2].clear()\n",
    "golden_cross_counts = {}\n",
    "for ticker in tickers:\n",
    "    golden_cross_counts[ticker] = trend_data[ticker]['Golden_Cross'].sum()\n",
    "\n",
    "bars = axes[1, 2].bar(golden_cross_counts.keys(), golden_cross_counts.values())\n",
    "axes[1, 2].set_title('Golden Cross Days Count')\n",
    "axes[1, 2].set_ylabel('Number of Days')\n",
    "for bar, count in zip(bars, golden_cross_counts.values()):\n",
    "    axes[1, 2].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 5,\n",
    "                    str(count), ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print trend summary\n",
    "print(\"Current Trend Status:\")\n",
    "for ticker in tickers:\n",
    "    data = trend_data[ticker]\n",
    "    latest = data.iloc[-1]\n",
    "    trend_status = \"ðŸŸ¢ Bullish\" if latest['Golden_Cross'] else \"ðŸ”´ Bearish\"\n",
    "    print(\n",
    "        f\"{ticker}: {trend_status} (MA20: ${latest['MA_20']:.2f}, MA50: ${latest['MA_50']:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516a5a33",
   "metadata": {},
   "source": [
    "#  Volatility Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0c0557",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nâš¡ VOLATILITY ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Calculate different volatility measures\n",
    "volatility_data = {}\n",
    "for ticker in tickers:\n",
    "    returns = calculate_returns(stock_data[ticker]['Close'])\n",
    "\n",
    "    # Rolling volatility (30-day)\n",
    "    rolling_vol = returns.rolling(30).std() * np.sqrt(252)\n",
    "\n",
    "    # GARCH-like simple volatility clustering\n",
    "    vol_clustering = returns.rolling(5).std()\n",
    "\n",
    "    # High-low volatility (Garman-Klass estimator)\n",
    "    high = stock_data[ticker]['High']\n",
    "    low = stock_data[ticker]['Low']\n",
    "    close = stock_data[ticker]['Close']\n",
    "    open_price = stock_data[ticker]['Open']\n",
    "\n",
    "    gk_vol = np.sqrt(0.5 * np.log(high/low)**2 -\n",
    "                     (2*np.log(2)-1) * np.log(close/open_price)**2)\n",
    "\n",
    "    volatility_data[ticker] = {\n",
    "        'returns': returns,\n",
    "        'rolling_vol': rolling_vol,\n",
    "        'vol_clustering': vol_clustering,\n",
    "        'gk_vol': gk_vol\n",
    "    }\n",
    "\n",
    "# Volatility visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Volatility Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Rolling volatility comparison\n",
    "for ticker in tickers:\n",
    "    axes[0, 0].plot(volatility_data[ticker]['rolling_vol'].index,\n",
    "                    volatility_data[ticker]['rolling_vol'],\n",
    "                    label=ticker, alpha=0.7)\n",
    "\n",
    "axes[0, 0].set_title('30-Day Rolling Volatility')\n",
    "axes[0, 0].set_ylabel('Annualized Volatility')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Volatility distribution\n",
    "vol_values = [volatility_data[ticker]['rolling_vol'].dropna()\n",
    "              for ticker in tickers]\n",
    "axes[0, 1].boxplot(vol_values, labels=tickers)\n",
    "axes[0, 1].set_title('Volatility Distribution by Stock')\n",
    "axes[0, 1].set_ylabel('Volatility')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Volatility clustering example (TSLA)\n",
    "tsla_returns = volatility_data['TSLA']['returns']\n",
    "axes[1, 0].plot(tsla_returns.index, tsla_returns, alpha=0.6)\n",
    "axes[1, 0].set_title('TSLA Returns (Volatility Clustering)')\n",
    "axes[1, 0].set_ylabel('Daily Returns')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Average volatility by stock\n",
    "avg_vols = {ticker: volatility_data[ticker]['rolling_vol'].mean()\n",
    "            for ticker in tickers}\n",
    "bars = axes[1, 1].bar(avg_vols.keys(), avg_vols.values())\n",
    "axes[1, 1].set_title('Average Volatility by Stock')\n",
    "axes[1, 1].set_ylabel('Volatility')\n",
    "for bar, vol in zip(bars, avg_vols.values()):\n",
    "    axes[1, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n",
    "                    f'{vol:.3f}', ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Volatility rankings\n",
    "print(\"Volatility Rankings (30-day average):\")\n",
    "vol_ranking = sorted(avg_vols.items(), key=lambda x: x[1], reverse=True)\n",
    "for i, (ticker, vol) in enumerate(vol_ranking, 1):\n",
    "    print(f\"{i}. {ticker}: {vol:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f0e467",
   "metadata": {},
   "source": [
    "#  Market Regime Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131ec6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸ”„ MARKET REGIME ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Simple regime identification based on VIX-like behavior\n",
    "# Using average volatility as a proxy for market stress\n",
    "\n",
    "# Calculate market-wide metrics\n",
    "market_returns = returns_df.mean(axis=1)  # Equal-weighted market\n",
    "market_vol = market_returns.rolling(30).std() * np.sqrt(252)\n",
    "\n",
    "# Define regimes based on volatility quartiles\n",
    "vol_q25 = market_vol.quantile(0.25)\n",
    "vol_q75 = market_vol.quantile(0.75)\n",
    "\n",
    "\n",
    "def get_regime(vol):\n",
    "    if vol <= vol_q25:\n",
    "        return 'Low Vol'\n",
    "    elif vol >= vol_q75:\n",
    "        return 'High Vol'\n",
    "    else:\n",
    "        return 'Normal'\n",
    "\n",
    "\n",
    "market_regime = market_vol.apply(get_regime)\n",
    "\n",
    "# Regime analysis visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "fig.suptitle('Market Regime Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Market volatility with regime coloring\n",
    "colors = {'Low Vol': 'green', 'Normal': 'blue', 'High Vol': 'red'}\n",
    "for regime in ['Low Vol', 'Normal', 'High Vol']:\n",
    "    mask = market_regime == regime\n",
    "    axes[0, 0].scatter(market_vol[mask].index, market_vol[mask],\n",
    "                       c=colors[regime], label=regime, alpha=0.6, s=10)\n",
    "\n",
    "axes[0, 0].set_title('Market Volatility Regimes')\n",
    "axes[0, 0].set_ylabel('Market Volatility')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Regime distribution\n",
    "regime_counts = market_regime.value_counts()\n",
    "axes[0, 1].pie(regime_counts.values, labels=regime_counts.index, autopct='%1.1f%%',\n",
    "               colors=[colors[regime] for regime in regime_counts.index])\n",
    "axes[0, 1].set_title('Regime Distribution')\n",
    "\n",
    "# Returns by regime\n",
    "regime_returns = {}\n",
    "for regime in ['Low Vol', 'Normal', 'High Vol']:\n",
    "    mask = market_regime == regime\n",
    "    regime_returns[regime] = market_returns[mask]\n",
    "\n",
    "axes[1, 0].boxplot([regime_returns[regime].dropna() for regime in ['Low Vol', 'Normal', 'High Vol']],\n",
    "                   labels=['Low Vol', 'Normal', 'High Vol'])\n",
    "axes[1, 0].set_title('Returns by Market Regime')\n",
    "axes[1, 0].set_ylabel('Daily Returns')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Stock performance by regime\n",
    "regime_performance = {}\n",
    "for ticker in tickers:\n",
    "    ticker_returns = returns_data[ticker]\n",
    "    perf = {}\n",
    "    for regime in ['Low Vol', 'Normal', 'High Vol']:\n",
    "        mask = market_regime == regime\n",
    "        aligned_returns = ticker_returns.reindex(market_regime.index)\n",
    "        perf[regime] = aligned_returns[mask].mean()\n",
    "    regime_performance[ticker] = perf\n",
    "\n",
    "perf_df = pd.DataFrame(regime_performance).T\n",
    "perf_df.plot(kind='bar', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Average Stock Returns by Regime')\n",
    "axes[1, 1].set_ylabel('Average Daily Return')\n",
    "axes[1, 1].legend(title='Regime')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Average Returns by Market Regime:\")\n",
    "for regime in ['Low Vol', 'Normal', 'High Vol']:\n",
    "    avg_return = market_returns[market_regime == regime].mean()\n",
    "    print(f\"{regime}: {avg_return:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5449a2",
   "metadata": {},
   "source": [
    "#  Summary and Key Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443bc436",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸŽ¯ KEY INSIGHTS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"1. STATISTICAL INSIGHTS:\")\n",
    "most_volatile = stats_df['Std_Return'].idxmax()\n",
    "least_volatile = stats_df['Std_Return'].idxmin()\n",
    "best_sharpe = stats_df['Sharpe_Ratio'].idxmax()\n",
    "print(f\"   â€¢ Most volatile: {most_volatile}\")\n",
    "print(f\"   â€¢ Least volatile: {least_volatile}\")\n",
    "print(f\"   â€¢ Best Sharpe ratio: {best_sharpe}\")\n",
    "\n",
    "print(\"\\n2. CORRELATION INSIGHTS:\")\n",
    "highest_corr_pair = returns_corr_flat.stack().idxmax()\n",
    "lowest_corr_pair = returns_corr_flat.stack().idxmin()\n",
    "print(\n",
    "    f\"   â€¢ Highest correlation: {highest_corr_pair[0]}-{highest_corr_pair[1]}\")\n",
    "print(f\"   â€¢ Lowest correlation: {lowest_corr_pair[0]}-{lowest_corr_pair[1]}\")\n",
    "\n",
    "print(\"\\n3. TREND INSIGHTS:\")\n",
    "bullish_stocks = [\n",
    "    ticker for ticker in tickers if trend_data[ticker].iloc[-1]['Golden_Cross']]\n",
    "bearish_stocks = [\n",
    "    ticker for ticker in tickers if not trend_data[ticker].iloc[-1]['Golden_Cross']]\n",
    "print(f\"   â€¢ Currently bullish: {bullish_stocks}\")\n",
    "print(f\"   â€¢ Currently bearish: {bearish_stocks}\")\n",
    "\n",
    "print(\"\\n4. VOLATILITY INSIGHTS:\")\n",
    "print(\n",
    "    f\"   â€¢ Highest average volatility: {vol_ranking[0][0]} ({vol_ranking[0][1]:.3f})\")\n",
    "print(\n",
    "    f\"   â€¢ Lowest average volatility: {vol_ranking[-1][0]} ({vol_ranking[-1][1]:.3f})\")\n",
    "\n",
    "print(\"\\n5. REGIME INSIGHTS:\")\n",
    "current_regime = market_regime.iloc[-1]\n",
    "regime_days = len(market_regime[market_regime == current_regime])\n",
    "print(f\"   â€¢ Current market regime: {current_regime}\")\n",
    "print(\n",
    "    f\"   â€¢ Days in high volatility regime: {len(market_regime[market_regime == 'High Vol'])}\")\n",
    "\n",
    "print(f\"\\nðŸ“Š EDA Analysis Complete!\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
