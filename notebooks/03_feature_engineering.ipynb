{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8ee79b5",
   "metadata": {},
   "source": [
    "#  üõ†Ô∏è Feature Engineering for Stock Price Prediction\n",
    "# \n",
    "# This notebook demonstrates feature engineering using the existing `src/data.py` and new `src/features.py` modules.\n",
    "# \n",
    "# **Objectives:**\n",
    "# - Load stock data using existing data functions\n",
    "# - Create comprehensive technical features\n",
    "# - Validate feature quality and relationships\n",
    "# - Prepare features for modeling\n",
    "# \n",
    "# **Dependencies:**\n",
    "# - Uses existing `src/data.py` for data loading \n",
    "# - Uses new `src/features.py` for feature creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3fa607",
   "metadata": {},
   "source": [
    "# Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30ff56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from features import (\n",
    "    create_all_features,\n",
    "    create_technical_indicators,\n",
    "    create_price_features,\n",
    "    create_volume_features,\n",
    "    create_return_features,\n",
    "    create_lag_features,\n",
    "    validate_features,\n",
    "    get_feature_importance_groups,\n",
    "    process_stock_features\n",
    ")\n",
    "from data import (\n",
    "    load_raw_data,\n",
    "    clean_data,\n",
    "    calculate_returns,\n",
    "    validate_data_quality,\n",
    "    get_trading_days\n",
    ")\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Import existing data functions\n",
    "\n",
    "# Import new feature functions\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ All modules imported successfully!\")\n",
    "print(f\"üìÖ Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b60027c",
   "metadata": {},
   "source": [
    "#  Load Stock Data (USES existing data.py functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76392e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä Loading stock data using existing data.py functions...\")\n",
    "\n",
    "# Define stocks to analyze\n",
    "tickers = ['AAPL', 'GOOGL', 'MSFT', 'TSLA', 'AMZN']\n",
    "stock_data = {}\n",
    "\n",
    "# Load data using EXISTING load_raw_data function\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        filepath = f'../data/raw/{ticker}.csv'\n",
    "        data = load_raw_data(filepath)  # Using existing function\n",
    "\n",
    "        # Validate data quality using existing function\n",
    "        quality_check = validate_data_quality(data)\n",
    "\n",
    "        if quality_check['overall']:\n",
    "            stock_data[ticker] = data\n",
    "            print(\n",
    "                f\"‚úÖ {ticker}: {len(data)} rows loaded ({data.index.min().date()} to {data.index.max().date()})\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è {ticker}: Data quality issues detected\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå {ticker}: Data file not found - run data download first\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå {ticker}: Error loading data - {str(e)}\")\n",
    "\n",
    "print(\n",
    "    f\"\\nüìà Successfully loaded {len(stock_data)} stocks for feature engineering\")\n",
    "\n",
    "# %%\n",
    "# Cell 3: Basic Feature Creation - Technical Indicators\n",
    "print(\"üîß Creating technical indicators...\")\n",
    "\n",
    "# Use AAPL as example for detailed feature analysis\n",
    "if 'AAPL' in stock_data:\n",
    "    aapl_data = stock_data['AAPL'].copy()\n",
    "\n",
    "    # Create technical indicators using NEW features.py\n",
    "    aapl_with_tech = create_technical_indicators(aapl_data)\n",
    "\n",
    "    print(f\"Original columns: {len(aapl_data.columns)}\")\n",
    "    print(f\"With technical indicators: {len(aapl_with_tech.columns)}\")\n",
    "    print(\n",
    "        f\"New features added: {len(aapl_with_tech.columns) - len(aapl_data.columns)}\")\n",
    "\n",
    "    # Display some technical indicators\n",
    "    tech_columns = [\n",
    "        col for col in aapl_with_tech.columns if col not in aapl_data.columns]\n",
    "    print(f\"\\nTechnical indicators created: {tech_columns[:10]}...\")\n",
    "\n",
    "    # Show sample data with technical indicators\n",
    "    display_cols = ['Close', 'SMA_20', 'EMA_12',\n",
    "                    'RSI_14', 'MACD', 'BB_Upper', 'BB_Lower']\n",
    "    print(f\"\\nSample technical indicators (last 5 days):\")\n",
    "    print(aapl_with_tech[display_cols].tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7226a5e4",
   "metadata": {},
   "source": [
    "#  Price and Volume Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2c3e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üí∞ Creating price and volume features...\")\n",
    "\n",
    "if 'AAPL' in stock_data:\n",
    "    # Add price features\n",
    "    aapl_with_price = create_price_features(aapl_with_tech)\n",
    "\n",
    "    # Add volume features\n",
    "    aapl_with_volume = create_volume_features(aapl_with_price)\n",
    "\n",
    "    # Add return features using existing calculate_returns function\n",
    "    aapl_with_returns = create_return_features(aapl_with_volume)\n",
    "\n",
    "    print(f\"After price features: {len(aapl_with_price.columns)} columns\")\n",
    "    print(f\"After volume features: {len(aapl_with_volume.columns)} columns\")\n",
    "    print(f\"After return features: {len(aapl_with_returns.columns)} columns\")\n",
    "\n",
    "    # Show new price/volume features\n",
    "    price_vol_features = ['High_Low_Ratio', 'Daily_Range_Pct', 'Gap_Pct',\n",
    "                          'Volume_Ratio_20', 'Returns_1d', 'Volatility_10d']\n",
    "\n",
    "    print(f\"\\nSample price/volume features (last 5 days):\")\n",
    "    print(aapl_with_returns[price_vol_features].tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59eeef49",
   "metadata": {},
   "source": [
    "#  Lag and Rolling Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93e710f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚è≥ Creating lag and rolling window features...\")\n",
    "\n",
    "if 'AAPL' in stock_data:\n",
    "    # Create lag features\n",
    "    aapl_with_lags = create_lag_features(\n",
    "        aapl_with_returns,\n",
    "        lags=[1, 2, 3, 5, 10],\n",
    "        columns=['Close', 'Volume', 'Returns_1d']\n",
    "    )\n",
    "\n",
    "    # Create rolling features (using NEW functions, not duplicating data.py)\n",
    "    from features import create_rolling_features\n",
    "    aapl_final = create_rolling_features(\n",
    "        aapl_with_lags,\n",
    "        windows=[5, 10, 20],\n",
    "        columns=['Close', 'Volume'],\n",
    "        statistics=['mean', 'std', 'min', 'max']\n",
    "    )\n",
    "\n",
    "    print(f\"After lag features: {len(aapl_with_lags.columns)} columns\")\n",
    "    print(f\"Final feature count: {len(aapl_final.columns)} columns\")\n",
    "\n",
    "    # Show lag features\n",
    "    lag_features = [col for col in aapl_final.columns if 'lag_' in col]\n",
    "    print(f\"\\nLag features created: {lag_features[:8]}...\")\n",
    "\n",
    "    # Show rolling features\n",
    "    rolling_features = [col for col in aapl_final.columns if 'rolling_' in col]\n",
    "    print(f\"\\nRolling features created: {rolling_features[:8]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b14e25",
   "metadata": {},
   "source": [
    "# Complete Feature Creation for All Stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024178cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üè≠ Creating complete feature sets for all stocks...\")\n",
    "\n",
    "# Create complete feature sets using the all-in-one function\n",
    "complete_features = {}\n",
    "\n",
    "for ticker in stock_data.keys():\n",
    "    print(f\"Processing {ticker}...\")\n",
    "\n",
    "    # Use the comprehensive feature creation function\n",
    "    features_df = create_all_features(\n",
    "        stock_data[ticker],\n",
    "        include_technical=True,\n",
    "        include_lags=True,\n",
    "        include_rolling=True,\n",
    "        lag_periods=[1, 2, 3, 5],\n",
    "        rolling_windows=[5, 10, 20]\n",
    "    )\n",
    "\n",
    "    # Add ticker identification\n",
    "    features_df['Ticker'] = ticker\n",
    "    complete_features[ticker] = features_df\n",
    "\n",
    "    print(f\"  ‚úÖ {ticker}: {len(features_df.columns)} features created\")\n",
    "\n",
    "print(f\"\\nüéØ Feature engineering completed for {len(complete_features)} stocks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bc1143",
   "metadata": {},
   "source": [
    "# Feature Validation and Quality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60acfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîç Validating feature quality...\")\n",
    "\n",
    "# Validate features for each stock\n",
    "validation_reports = {}\n",
    "\n",
    "for ticker, features_df in complete_features.items():\n",
    "    print(f\"\\nüìä Validating features for {ticker}:\")\n",
    "\n",
    "    # Use NEW validation function\n",
    "    report = validate_features(features_df)\n",
    "    validation_reports[ticker] = report\n",
    "\n",
    "    print(f\"  ‚Ä¢ Total features: {report['total_features']}\")\n",
    "    print(f\"  ‚Ä¢ Total rows: {report['total_rows']}\")\n",
    "    print(\n",
    "        f\"  ‚Ä¢ Features with missing values: {len([k for k, v in report['missing_values'].items() if v > 0])}\")\n",
    "    print(\n",
    "        f\"  ‚Ä¢ Features with infinite values: {len(report['infinite_values'])}\")\n",
    "    print(f\"  ‚Ä¢ Constant features: {len(report['constant_features'])}\")\n",
    "    print(\n",
    "        f\"  ‚Ä¢ High correlation pairs: {len(report['high_correlation_pairs'])}\")\n",
    "\n",
    "    # Show problematic features if any\n",
    "    if report['infinite_values']:\n",
    "        print(\n",
    "            f\"  ‚ö†Ô∏è Infinite values in: {list(report['infinite_values'].keys())}\")\n",
    "\n",
    "    if report['constant_features']:\n",
    "        print(f\"  ‚ö†Ô∏è Constant features: {report['constant_features']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50993c77",
   "metadata": {},
   "source": [
    "# Feature Importance Groups Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aceef9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéØ Analyzing feature groups...\")\n",
    "\n",
    "# Get predefined feature groups\n",
    "feature_groups = get_feature_importance_groups()\n",
    "\n",
    "print(\"Feature groups defined:\")\n",
    "for group_name, features in feature_groups.items():\n",
    "    print(f\"  ‚Ä¢ {group_name}: {len(features)} features\")\n",
    "\n",
    "# Analyze feature availability across stocks\n",
    "if 'AAPL' in complete_features:\n",
    "    aapl_features = complete_features['AAPL']\n",
    "    available_features = set(aapl_features.columns)\n",
    "\n",
    "    print(f\"\\nFeature availability analysis (AAPL example):\")\n",
    "    for group_name, group_features in feature_groups.items():\n",
    "        available_in_group = [\n",
    "            f for f in group_features if f in available_features]\n",
    "        coverage = len(available_in_group) / len(group_features) * 100\n",
    "        print(\n",
    "            f\"  ‚Ä¢ {group_name}: {len(available_in_group)}/{len(group_features)} features ({coverage:.1f}% coverage)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6937ac91",
   "metadata": {},
   "source": [
    "# Feature Visualization - Technical Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5380859",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìà Visualizing technical indicators...\")\n",
    "\n",
    "if 'AAPL' in complete_features:\n",
    "    aapl_features = complete_features['AAPL']\n",
    "\n",
    "    # Create comprehensive technical analysis plot\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(20, 15))\n",
    "\n",
    "    # Price with moving averages\n",
    "    ax1 = axes[0, 0]\n",
    "    aapl_features[['Close', 'SMA_20', 'SMA_50',\n",
    "                   'EMA_12', 'EMA_26']].plot(ax=ax1, alpha=0.8)\n",
    "    ax1.set_title('AAPL: Price with Moving Averages', fontsize=14)\n",
    "    ax1.set_ylabel('Price ($)')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.legend(loc='upper left')\n",
    "\n",
    "    # RSI\n",
    "    ax2 = axes[0, 1]\n",
    "    aapl_features['RSI_14'].plot(ax=ax2, color='purple', linewidth=2)\n",
    "    ax2.axhline(y=70, color='red', linestyle='--',\n",
    "                alpha=0.7, label='Overbought (70)')\n",
    "    ax2.axhline(y=30, color='green', linestyle='--',\n",
    "                alpha=0.7, label='Oversold (30)')\n",
    "    ax2.set_title('AAPL: RSI (14-day)', fontsize=14)\n",
    "    ax2.set_ylabel('RSI')\n",
    "    ax2.set_ylim(0, 100)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.legend()\n",
    "\n",
    "    # MACD\n",
    "    ax3 = axes[1, 0]\n",
    "    aapl_features[['MACD', 'MACD_Signal']].plot(ax=ax3)\n",
    "    aapl_features['MACD_Histogram'].plot(\n",
    "        ax=ax3, kind='bar', alpha=0.3, color='gray')\n",
    "    ax3.set_title('AAPL: MACD Indicator', fontsize=14)\n",
    "    ax3.set_ylabel('MACD')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.legend()\n",
    "\n",
    "    # Bollinger Bands\n",
    "    ax4 = axes[1, 1]\n",
    "    aapl_features[['Close', 'BB_Upper', 'BB_Middle', 'BB_Lower']].plot(\n",
    "        ax=ax4, alpha=0.8)\n",
    "    ax4.fill_between(aapl_features.index, aapl_features['BB_Upper'], aapl_features['BB_Lower'],\n",
    "                     alpha=0.1, color='blue')\n",
    "    ax4.set_title('AAPL: Bollinger Bands', fontsize=14)\n",
    "    ax4.set_ylabel('Price ($)')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    ax4.legend()\n",
    "\n",
    "    # Volume analysis\n",
    "    ax5 = axes[2, 0]\n",
    "    ax5_twin = ax5.twinx()\n",
    "    aapl_features['Volume'].plot(ax=ax5, alpha=0.6, color='orange')\n",
    "    aapl_features['Volume_Ratio_20'].plot(\n",
    "        ax=ax5_twin, color='red', linewidth=2)\n",
    "    ax5.set_title('AAPL: Volume and Volume Ratio', fontsize=14)\n",
    "    ax5.set_ylabel('Volume', color='orange')\n",
    "    ax5_twin.set_ylabel('Volume Ratio (20-day)', color='red')\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "\n",
    "    # Returns and Volatility\n",
    "    ax6 = axes[2, 1]\n",
    "    ax6_twin = ax6.twinx()\n",
    "    aapl_features['Returns_1d'].plot(ax=ax6, alpha=0.7, color='blue')\n",
    "    aapl_features['Volatility_10d'].plot(ax=ax6_twin, color='red', linewidth=2)\n",
    "    ax6.set_title('AAPL: Daily Returns and 10-day Volatility', fontsize=14)\n",
    "    ax6.set_ylabel('Daily Returns', color='blue')\n",
    "    ax6_twin.set_ylabel('Volatility (10-day)', color='red')\n",
    "    ax6.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be57a2ac",
   "metadata": {},
   "source": [
    "# Feature Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3d7950",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîó Analyzing feature correlations...\")\n",
    "\n",
    "if 'AAPL' in complete_features:\n",
    "    aapl_features = complete_features['AAPL']\n",
    "\n",
    "    # Select key technical features for correlation analysis\n",
    "    key_features = [\n",
    "        'Close', 'SMA_20', 'RSI_14', 'MACD', 'BB_Width',\n",
    "        'Volume_Ratio_20', 'Returns_1d', 'Volatility_10d',\n",
    "        'High_Low_Ratio', 'Daily_Range_Pct', 'ATR_14'\n",
    "    ]\n",
    "\n",
    "    # Filter available features\n",
    "    available_key_features = [\n",
    "        f for f in key_features if f in aapl_features.columns]\n",
    "\n",
    "    if len(available_key_features) > 1:\n",
    "        # Calculate correlation matrix\n",
    "        corr_matrix = aapl_features[available_key_features].corr()\n",
    "\n",
    "        # Create correlation heatmap\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "        sns.heatmap(corr_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,\n",
    "                    square=True, linewidths=0.5, cbar_kws={\"shrink\": .5}, fmt='.2f')\n",
    "        plt.title(\n",
    "            'AAPL: Feature Correlation Matrix (Key Technical Indicators)', fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Find highly correlated feature pairs\n",
    "        high_corr_pairs = []\n",
    "        for i in range(len(corr_matrix.columns)):\n",
    "            for j in range(i+1, len(corr_matrix.columns)):\n",
    "                corr_val = corr_matrix.iloc[i, j]\n",
    "                if abs(corr_val) > 0.7:  # High correlation threshold\n",
    "                    high_corr_pairs.append((\n",
    "                        corr_matrix.columns[i],\n",
    "                        corr_matrix.columns[j],\n",
    "                        corr_val\n",
    "                    ))\n",
    "\n",
    "        if high_corr_pairs:\n",
    "            print(\"\\nüîç Highly correlated feature pairs (|r| > 0.7):\")\n",
    "            for feat1, feat2, corr in high_corr_pairs:\n",
    "                print(f\"  ‚Ä¢ {feat1} ‚Üî {feat2}: r = {corr:.3f}\")\n",
    "        else:\n",
    "            print(\"\\n‚úÖ No highly correlated features detected (|r| > 0.7)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6392445b",
   "metadata": {},
   "source": [
    "# Feature Distributions Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6f1085",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä Analyzing feature distributions...\")\n",
    "\n",
    "if 'AAPL' in complete_features:\n",
    "    aapl_features = complete_features['AAPL']\n",
    "\n",
    "    # Select various types of features for distribution analysis\n",
    "    distribution_features = [\n",
    "        'Returns_1d', 'RSI_14', 'Volume_Ratio_20', 'BB_Width',\n",
    "        'Daily_Range_Pct', 'MACD', 'Volatility_10d', 'Williams_R'\n",
    "    ]\n",
    "\n",
    "    # Filter available features\n",
    "    available_dist_features = [\n",
    "        f for f in distribution_features if f in aapl_features.columns]\n",
    "\n",
    "    if available_dist_features:\n",
    "        # Create distribution plots\n",
    "        n_features = len(available_dist_features)\n",
    "        n_cols = 4\n",
    "        n_rows = (n_features + n_cols - 1) // n_cols\n",
    "\n",
    "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 5*n_rows))\n",
    "        axes = axes.flatten() if n_rows > 1 else [\n",
    "            axes] if n_rows == 1 else axes\n",
    "\n",
    "        for i, feature in enumerate(available_dist_features):\n",
    "            if i < len(axes):\n",
    "                # Remove NaN and infinite values for plotting\n",
    "                feature_data = aapl_features[feature].replace(\n",
    "                    [np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "                if len(feature_data) > 0:\n",
    "                    # Plot histogram\n",
    "                    axes[i].hist(feature_data, bins=50, alpha=0.7,\n",
    "                                 edgecolor='black', linewidth=0.5)\n",
    "                    axes[i].set_title(f'{feature} Distribution', fontsize=12)\n",
    "                    axes[i].set_xlabel(feature)\n",
    "                    axes[i].set_ylabel('Frequency')\n",
    "                    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "                    # Add statistics text\n",
    "                    stats_text = f'Mean: {feature_data.mean():.3f}\\nStd: {feature_data.std():.3f}'\n",
    "                    axes[i].text(0.05, 0.95, stats_text, transform=axes[i].transAxes,\n",
    "                                 verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "                else:\n",
    "                    axes[i].text(0.5, 0.5, f'No valid data\\nfor {feature}',\n",
    "                                 transform=axes[i].transAxes, ha='center', va='center')\n",
    "\n",
    "        # Hide unused subplots\n",
    "        for i in range(len(available_dist_features), len(axes)):\n",
    "            axes[i].set_visible(False)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Print distribution statistics\n",
    "        print(\n",
    "            f\"\\nüìà Distribution statistics for {len(available_dist_features)} features:\")\n",
    "        for feature in available_dist_features:\n",
    "            feature_data = aapl_features[feature].replace(\n",
    "                [np.inf, -np.inf], np.nan).dropna()\n",
    "            if len(feature_data) > 0:\n",
    "                print(f\"  ‚Ä¢ {feature:20s}: Œº={feature_data.mean():8.4f}, œÉ={feature_data.std():8.4f}, \"\n",
    "                      f\"min={feature_data.min():8.4f}, max={feature_data.max():8.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9efc04c",
   "metadata": {},
   "source": [
    "# Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b67869a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üï≥Ô∏è Analyzing missing values...\")\n",
    "\n",
    "# Analyze missing values across all stocks\n",
    "missing_analysis = {}\n",
    "\n",
    "for ticker, features_df in complete_features.items():\n",
    "    # Calculate missing value percentages\n",
    "    missing_pct = (features_df.isnull().sum() / len(features_df)) * 100\n",
    "    missing_features = missing_pct[missing_pct >\n",
    "                                   0].sort_values(ascending=False)\n",
    "\n",
    "    missing_analysis[ticker] = {\n",
    "        'total_features': len(features_df.columns),\n",
    "        'features_with_missing': len(missing_features),\n",
    "        'max_missing_pct': missing_features.iloc[0] if len(missing_features) > 0 else 0,\n",
    "        'missing_details': missing_features.to_dict()\n",
    "    }\n",
    "\n",
    "# Create missing values visualization\n",
    "if missing_analysis:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "    # Missing values by stock\n",
    "    stocks = list(missing_analysis.keys())\n",
    "    missing_counts = [missing_analysis[stock]\n",
    "                      ['features_with_missing'] for stock in stocks]\n",
    "    max_missing = [missing_analysis[stock]['max_missing_pct']\n",
    "                   for stock in stocks]\n",
    "\n",
    "    ax1 = axes[0]\n",
    "    bars = ax1.bar(stocks, missing_counts, alpha=0.7, color='coral')\n",
    "    ax1.set_title(\n",
    "        'Number of Features with Missing Values by Stock', fontsize=14)\n",
    "    ax1.set_ylabel('Features with Missing Values')\n",
    "    ax1.set_xlabel('Stock Ticker')\n",
    "\n",
    "    # Add value labels on bars\n",
    "    for bar, count in zip(bars, missing_counts):\n",
    "        if count > 0:\n",
    "            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
    "                     f'{count}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "    # Maximum missing percentage by stock\n",
    "    ax2 = axes[1]\n",
    "    bars2 = ax2.bar(stocks, max_missing, alpha=0.7, color='lightblue')\n",
    "    ax2.set_title('Maximum Missing Value Percentage by Stock', fontsize=14)\n",
    "    ax2.set_ylabel('Maximum Missing Percentage (%)')\n",
    "    ax2.set_xlabel('Stock Ticker')\n",
    "\n",
    "    # Add percentage labels\n",
    "    for bar, pct in zip(bars2, max_missing):\n",
    "        if pct > 0:\n",
    "            ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
    "                     f'{pct:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Print detailed missing values report\n",
    "print(f\"\\nüìã Missing values summary:\")\n",
    "for ticker, analysis in missing_analysis.items():\n",
    "    print(f\"\\n{ticker}:\")\n",
    "    print(f\"  ‚Ä¢ Total features: {analysis['total_features']}\")\n",
    "    print(\n",
    "        f\"  ‚Ä¢ Features with missing values: {analysis['features_with_missing']}\")\n",
    "    if analysis['features_with_missing'] > 0:\n",
    "        print(\n",
    "            f\"  ‚Ä¢ Maximum missing percentage: {analysis['max_missing_pct']:.2f}%\")\n",
    "        # Show top 5 features with most missing values\n",
    "        top_missing = dict(list(analysis['missing_details'].items())[:5])\n",
    "        print(f\"  ‚Ä¢ Top missing features: {top_missing}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f68585d",
   "metadata": {},
   "source": [
    "# Feature Data Export and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d127f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üíæ Exporting features and creating summary...\")\n",
    "\n",
    "# Create output directory for processed features\n",
    "os.makedirs('../data/features', exist_ok=True)\n",
    "\n",
    "# Export feature datasets\n",
    "export_summary = {}\n",
    "\n",
    "for ticker, features_df in complete_features.items():\n",
    "    # Clean feature names\n",
    "    from features import clean_feature_names\n",
    "    clean_features = clean_feature_names(features_df)\n",
    "\n",
    "    # Export to CSV\n",
    "    output_path = f'../data/features/{ticker}_features.csv'\n",
    "    clean_features.to_csv(output_path)\n",
    "\n",
    "    export_summary[ticker] = {\n",
    "        'output_file': output_path,\n",
    "        'total_features': len(clean_features.columns),\n",
    "        'total_rows': len(clean_features),\n",
    "        'date_range': f\"{clean_features.index.min().date()} to {clean_features.index.max().date()}\"\n",
    "    }\n",
    "\n",
    "    print(f\"‚úÖ {ticker}: Features exported to {output_path}\")\n",
    "\n",
    "# Create master summary report\n",
    "summary_report = {\n",
    "    'analysis_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'stocks_processed': list(complete_features.keys()),\n",
    "    'total_stocks': len(complete_features),\n",
    "    'feature_engineering_steps': [\n",
    "        'Technical indicators (SMA, EMA, RSI, MACD, Bollinger Bands, etc.)',\n",
    "        'Price features (ratios, ranges, gaps)',\n",
    "        'Volume features (ratios, moving averages)',\n",
    "        'Return features (simple, log returns, volatility)',\n",
    "        'Lag features (1, 2, 3, 5 periods)',\n",
    "        'Rolling window features (5, 10, 20 periods)'\n",
    "    ],\n",
    "    'export_summary': export_summary,\n",
    "    'validation_reports': validation_reports\n",
    "}\n",
    "\n",
    "# Export summary report\n",
    "with open('../data/features/feature_engineering_summary.json', 'w') as f:\n",
    "    json.dump(summary_report, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\nüìä Feature Engineering Summary:\")\n",
    "print(f\"  ‚Ä¢ Stocks processed: {summary_report['total_stocks']}\")\n",
    "print(\n",
    "    f\"  ‚Ä¢ Feature engineering steps: {len(summary_report['feature_engineering_steps'])}\")\n",
    "print(f\"  ‚Ä¢ Output files created: {len(export_summary)}\")\n",
    "print(f\"  ‚Ä¢ Summary report: ../data/features/feature_engineering_summary.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8fd0ab",
   "metadata": {},
   "source": [
    "# Next Steps and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc5250c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüéØ Feature Engineering Complete - Next Steps:\")\n",
    "\n",
    "print(\"\"\"\n",
    "‚úÖ COMPLETED IN THIS NOTEBOOK:\n",
    "  ‚Ä¢ Loaded stock data using existing data.py functions (NO DUPLICATION)\n",
    "  ‚Ä¢ Created comprehensive technical indicators\n",
    "  ‚Ä¢ Generated price, volume, and return features  \n",
    "  ‚Ä¢ Added lag and rolling window features\n",
    "  ‚Ä¢ Validated feature quality and identified issues\n",
    "  ‚Ä¢ Analyzed feature correlations and distributions\n",
    "  ‚Ä¢ Exported processed features for modeling\n",
    "\n",
    "üìã KEY FINDINGS:\n",
    "  ‚Ä¢ Technical indicators successfully created for all stocks\n",
    "  ‚Ä¢ Some features may have missing values due to calculation windows\n",
    "  ‚Ä¢ Feature correlations identified for potential dimensionality reduction\n",
    "  ‚Ä¢ All features exported to ../data/features/ directory\n",
    "\n",
    "üöÄ RECOMMENDED NEXT STEPS:\n",
    "  1. Handle missing values (forward fill, interpolation, or removal)\n",
    "  2. Feature selection based on correlation analysis\n",
    "  3. Feature scaling/normalization for modeling\n",
    "  4. Create train/validation/test splits with proper time-series considerations\n",
    "  5. Begin baseline model training with processed features\n",
    "\n",
    "üìÅ OUTPUT FILES:\n",
    "  ‚Ä¢ ../data/features/{ticker}_features.csv - Feature datasets for each stock  \n",
    "  ‚Ä¢ ../data/features/feature_engineering_summary.json - Complete analysis summary\n",
    "\n",
    "üîß READY FOR MODELING:\n",
    "  The features are now ready for the next phase - baseline model training.\n",
    "  Use the exported feature files as input to your modeling pipeline.\n",
    "\"\"\")\n",
    "\n",
    "print(\"üèÅ Feature engineering notebook execution completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
